{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "            '''                        CS 637\n",
    "                                     Homework - 1\n",
    "                                  KUSHAL SHANKAR RAJ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Design and Implementation:\n",
    "\n",
    "Program design consists of a Neural_Network class which contains methods like weight_initialization, \n",
    "forward_pass, backward_pass, update_weights. \n",
    "\n",
    "Program designed for datasets like MNIST and Madison_Irrigated and rain dataset.\n",
    "\n",
    "The model is the first function which is called for training the neural network. \n",
    "Depending on the length of the layer dimension list the weight and bias are initialized\n",
    "and put into a parameters dictionary. \n",
    "\n",
    "Then, the forward_pass takes these parameters and executes and gives the output.\n",
    "This output is used to calculate the loss then backpropagate the error through the network. \n",
    "\n",
    "User is given option to choose Relu or Sigmoid as activation function. \n",
    "Softmax at the output layer for classification and cross entropy as loss function.\n",
    "\n",
    "The program is generalized in a way that the number of parameters of the neural network \n",
    "can be customised according the user’s flexibility. \n",
    "\n",
    "Various parameters are:\n",
    "\n",
    "\tUser_Input: The neural network accepts an input with any dimension. \n",
    "                The input can be multiclass, change in number of classes will not matter. \n",
    "                The neural network classifies any number of classes.\n",
    "\n",
    "\tHidden_layers:  The number of hidden layers are declared dynamically in the neural network\n",
    "                    at the time of training the neural network. Any number of hidden layers can be added.\n",
    "                    \n",
    "\tActivation_function: Depending on the activation function specified in the function call,\n",
    "                         various activation functions such as sigmoid or relu can be selected.\n",
    "                         \n",
    "\tLearning rate and epochs: The learning rate and the number of iterations for training of the\n",
    "                               test data can be passed as an argument'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f3ac8e8567fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mnist'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 01. MNIST DATA SET \n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "#DATA PREPROCESSING\n",
    "#--------------------\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "%matplotlib inline\n",
    "import math\n",
    "import sklearn.preprocessing as norm\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Reshapping and Normalizing given input data\n",
    "input_data = np.asarray(x_train)\n",
    "training_data = input_data.reshape(60000,784)\n",
    "training_data = training_data.T\n",
    "training_Completedata = norm.normalize(training_data)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "training_Completelabels = np.asarray(y_train).T\n",
    "\n",
    "\n",
    "testing_data = np.asarray(x_test)\n",
    "testing_data = testing_data.reshape(10000,784)\n",
    "testing_data = testing_data.T\n",
    "testing_Completedata = norm.normalize(testing_data)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "testing_Completelabels = np.asarray(y_test).T\n",
    "\n",
    "print(training_Completedata.shape,training_Completelabels.shape,testing_Completedata.shape,testing_Completelabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile = r'Madison_Irrigated.xls'\\ndf1 = pd.read_excel(file)\\n\\nfile = r'Madison_Rainfed.xls'\\ndf2 = pd.read_excel(file)\\n\\nframes = pd.concat([df1, df2])\\ntraining_data = frames.fillna(0)\\ntraining_data = training_data.to_numpy()\\n#print(type(training_data))\\n\\nzero1 = np.zeros(1288)\\none1 = np.ones(1288)\\nlabel_Irrigated = np.array([zero1,one1])\\n\\nzero2 = np.zeros(5053)\\none2 = np.ones(5053)\\nlabel_Rain = np.array([one2,zero2])\\n\\ntrain_labels = np.append(label_Irrigated,label_Rain,axis = 1).T\\n\\ntraining_data = np.take(training_data,np.random.permutation(training_data.shape[0]),axis=0,out=training_data)\\ntrain_labels = np.take(train_labels,np.random.permutation(train_labels.shape[0]),axis=0,out=train_labels)\\ntraining = norm.normalize(training_data)\\n\\n#Train and test split \\nX_train, X_test, y_train, y_test = train_test_split(training, train_labels, test_size=0.30, random_state=0)\\n\\nX_training = X_train.T\\nX_testing = X_test.T\\ny_training = y_train.T\\ny_testing = y_test.T\\n\\nprint(X_training.shape,y_training.shape,X_testing.shape,y_testing.shape)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 02. Madison_IrrigatedRain DATA SET \n",
    "#--------------------------------------------------------\n",
    "\n",
    "#DATA PREPROCESSING\n",
    "#--------------------\n",
    "\n",
    "file = r'Madison_Irrigated.xls'\n",
    "df1 = pd.read_excel(file)\n",
    "\n",
    "file = r'Madison_Rainfed.xls'\n",
    "df2 = pd.read_excel(file)\n",
    "\n",
    "frames = pd.concat([df1, df2])\n",
    "training_data = frames.fillna(0)\n",
    "training_data = training_data.to_numpy()\n",
    "#print(type(training_data))\n",
    "\n",
    "zero1 = np.zeros(1288)\n",
    "one1 = np.ones(1288)\n",
    "label_Irrigated = np.array([zero1,one1])\n",
    "\n",
    "zero2 = np.zeros(5053)\n",
    "one2 = np.ones(5053)\n",
    "label_Rain = np.array([one2,zero2])\n",
    "\n",
    "train_labels = np.append(label_Irrigated,label_Rain,axis = 1).T\n",
    "\n",
    "training_data = np.take(training_data,np.random.permutation(training_data.shape[0]),axis=0,out=training_data)\n",
    "train_labels = np.take(train_labels,np.random.permutation(train_labels.shape[0]),axis=0,out=train_labels)\n",
    "training = norm.normalize(training_data)\n",
    "\n",
    "#Train and test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(training, train_labels, test_size=0.30, random_state=0)\n",
    "\n",
    "X_training = X_train.T\n",
    "X_testing = X_test.T\n",
    "y_training = y_train.T\n",
    "y_testing = y_test.T\n",
    "\n",
    "print(X_training.shape,y_training.shape,X_testing.shape,y_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_network:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #Size are 784, 32 & 10\n",
    "    def model(self,training_data,train_labels,testing_data,testing_labels,learning_rate,hidden_size, batch_size,activation,num_iterations):\n",
    "        \n",
    "         #__MODEL__WEIGHTS\n",
    "        global layer1_weights\n",
    "        global layer1_biases\n",
    "        global layer2_weights\n",
    "        global layer2_biases\n",
    "        list_name = []\n",
    "        \n",
    "        #set input sizes\n",
    "        training_data = training_data\n",
    "        hidden_size = hidden_size\n",
    "        learning_rate = learning_rate\n",
    "        batch_size = batch_size\n",
    "        num_iterations = num_iterations\n",
    "        activation = activation\n",
    "        train_labels = train_labels\n",
    "        \n",
    "        iter_cal = (((int(len(training_data[0])/batch_size))+1) - ((len(training_data[0]))/batch_size))\n",
    "        count = int(iter_cal * batch_size)\n",
    "        \n",
    "        #Set Iterator\n",
    "        train_1 = training_data\n",
    "        \n",
    "        if(count!=0):\n",
    "            train_1 = np.append(training_data,training_data[:,0:count],axis = 1)\n",
    "        \n",
    "        test_1 = train_labels\n",
    "        \n",
    "        if(count!=0):\n",
    "            test_1 = np.append(train_labels,train_labels[:,0:count],axis = 1)\n",
    "        \n",
    "        #encoding training labels \n",
    "        encoding_labels = self.accuracy_cal(test_1)\n",
    "        \n",
    "        #Initial parameters initialisations for given batch size\n",
    "        initial_training = train_1[:,0:batch_size]\n",
    "        \n",
    "        #class labels\n",
    "        class_labels = len(test_1)\n",
    "       \n",
    "        #Set parameters\n",
    "        parameters = self.initialize_parameters(hidden_size,initial_training,class_labels, batch_size)\n",
    "        \n",
    "        iter = int(len(train_1[0])/batch_size) \n",
    "        \n",
    "        #to store final predictons and accuracy after training\n",
    "        final_output = []\n",
    "        accuracy_results = []\n",
    "        \n",
    "        for p in range(num_iterations):\n",
    "            \n",
    "            k=0  \n",
    "            j=batch_size\n",
    "            \n",
    "             #Array to append loss\n",
    "            J = []\n",
    "            list_name.clear()\n",
    "            \n",
    "            for q in range(iter):\n",
    "                \n",
    "                train_data = train_1[:,k:j]\n",
    "\n",
    "                train_ytrain = test_1[:,k:j]\n",
    "\n",
    "\n",
    "                #forward propagation\n",
    "                output,activation1,Output_layer2 = self.forward_propagation(train_data,parameters,activation)\n",
    "\n",
    "                #softmax encoding for accuracy\n",
    "                col = output.shape[1]        \n",
    "                row = output.shape[0]  \n",
    "                \n",
    "                for i in range(col):\n",
    "                    arr = np.argmax(output[:row,i])\n",
    "                    list_name.append(arr)    \n",
    "                labels = np.asarray(list_name)\n",
    "                \n",
    "                #calculate the loss\n",
    "                loss = self.cal_loss(train_ytrain,output)\n",
    "                \n",
    "                #Back propagation\n",
    "                gradient_w1,gradient_b1,gradient_w2,gradient_b2 = self.backward_propagation(Output_layer2,train_data,train_ytrain,activation1,parameters,activation)\n",
    "\n",
    "                #update the parameters\n",
    "                parameters = self.update_parameters(learning_rate,gradient_w1,gradient_b1,gradient_w2,gradient_b2,parameters)\n",
    "\n",
    "                #append loss\n",
    "                J.append(loss)\n",
    "                \n",
    "                #Increment for next batch (Batch_size)\n",
    "                k += batch_size\n",
    "                j += batch_size\n",
    "                \n",
    "                #print(q,\"...\",iter)\n",
    "                #Print accuracy after every epoch\n",
    "                if(q==(iter-1)):\n",
    "                    cal = np.sum(labels==encoding_labels)\n",
    "                    evaluation = ((cal/len(training_data[0])) *100)\n",
    "                    print(\"Iteration  :\",p+1,\" (Epoch)   Accuracy = \",evaluation,\" %\")\n",
    "                    accuracy_results.append(evaluation)\n",
    "            \n",
    "            #Append FINAL COST and FINAL OUTPUT\n",
    "            final = np.sum(J) \n",
    "            final_output.append(final)  \n",
    "        \n",
    "        #print(testing_data.shape,testing_labels.shape)\n",
    "        fina_acc = evaluation\n",
    "        self.test_inputdata(testing_data,testing_labels,parameters,batch_size,activation,fina_acc)\n",
    "        #PLOT LOSS AND ACCURACY VS NO: OF INTERATIONS\n",
    "        print(\"-----------------------------------------------------\\n\\nCost_Plot\")\n",
    "        self.plot_loss(final_output)\n",
    "        print(\"-----------------------------------------------------\\n\\nAccuracy\")\n",
    "        self.plot_accu(accuracy_results)\n",
    "        \n",
    "        \n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "#_________________FUNCTIONs________________\n",
    "        \n",
    "    \n",
    "    #Testing input and labels Implementation\n",
    "    def test_inputdata(self,testing_data,testing_labels,parameters,batch_size,activation,fina_acc):\n",
    "        k=0  \n",
    "        j=batch_size\n",
    "        \n",
    "        list_one = []\n",
    "        list_two = []\n",
    "        \n",
    "         #Set Iterator\n",
    "        iter = int(len(testing_data[0])/batch_size)\n",
    "        \n",
    "        count = iter * batch_size\n",
    "        \n",
    "        test = testing_data[:,0:count]\n",
    "        testing_data = test\n",
    "        \n",
    "        label = testing_labels[:,0:count]\n",
    "        testing_labels = label\n",
    "        \n",
    "        encoding_labels = self.accuracy_cal(testing_labels)\n",
    "            \n",
    "        for q in range(iter):\n",
    "                \n",
    "            #print(\"k and j: \", k,\"  \",j)\n",
    "            test_data = testing_data[:,k:j]\n",
    "                \n",
    "            #print(\"train:  \",training_data.shape)\n",
    "            test_ytest = testing_labels[:,k:j]\n",
    "                \n",
    "            #print(\"train_labels:  \",train_labels.shape)\n",
    "\n",
    "            #forward propagation\n",
    "            output,activation1,Output_layer2 = self.forward_propagation(test_data,parameters,activation)\n",
    "                \n",
    "            #softmax encoding for accuracy\n",
    "            col = output.shape[1]        \n",
    "            row = output.shape[0]\n",
    "                \n",
    "            for i in range(col):\n",
    "                arr = np.argmax(output[:row,i])\n",
    "                list_two.append(arr)    \n",
    "            labels = np.asarray(list_two)\n",
    "                \n",
    "            #Increment for next batch (Batch_size)\n",
    "            k += batch_size\n",
    "            j += batch_size\n",
    "                \n",
    "        #Print accuracy after every epoch\n",
    "        cal = np.sum(labels==encoding_labels)\n",
    "        print(\"-----------------------------------------------------\\n\\nTest Accuracy = \",((cal/(len(testing_data[0]))) *100),\" %\")\n",
    "    \n",
    "    \n",
    "    #Labels Encoding\n",
    "    def accuracy_cal(self,Complete_labels):\n",
    "        length = Complete_labels.shape[1]\n",
    "        row = Complete_labels.shape[0]\n",
    "        \n",
    "        index = []\n",
    "        for i in range(length):\n",
    "            for j in range(row):\n",
    "                ones = Complete_labels[j,i]\n",
    "                if(ones == 1):\n",
    "                    index.append(j)\n",
    "\n",
    "        labels_encoding = np.asarray(index)\n",
    "        \n",
    "        return labels_encoding\n",
    "    \n",
    "    \n",
    "    #Relu activation\n",
    "    def rectified(self,Z):\n",
    "        return np.maximum(0,Z)\n",
    "    \n",
    "    \n",
    "    #Relu or Sigmoid derivative optional\n",
    "    def deriv_activation(self,var, Z):\n",
    "        if (var == \"relu\"):\n",
    "            z = 1 * (Z > 0)\n",
    "        else:\n",
    "            z = Z * (1 - Z)\n",
    "        return z\n",
    "    \n",
    "    \n",
    "    #Sigmoid\n",
    "    def sigmoid(self,Z):\n",
    "        z = 1/(1 + np.exp(-Z))\n",
    "        return z\n",
    "    \n",
    "    \n",
    "    #softmax function for output\n",
    "    def softmax(self,x):\n",
    "        exponentials = np.exp(x)\n",
    "        sum_exponentials = np.sum(exponentials)\n",
    "        result = exponentials/sum_exponentials\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Initialize parameters\n",
    "    def initialize_parameters(self,hidden_units,training_data, output_units,batch_size):\n",
    "        \n",
    "        mean = 0        #mean of parameters \n",
    "        std = 1         #standard deviation\n",
    "            \n",
    "        input_units = len(training_data)\n",
    "\n",
    "        layer1_weights = np.random.normal(mean,std,(hidden_units,input_units))           #100,784     \n",
    "        layer1_biases = np.random.rand(hidden_units,batch_size)                          #100,32           \n",
    "        layer2_weights = np.random.normal(mean,std,(output_units,hidden_units))          #10,100\n",
    "        layer2_biases = np.random.rand(output_units,batch_size)                          #10,32\n",
    "        \n",
    "        #dictionary to hold key and value pairs\n",
    "        parameters = dict()\n",
    "        parameters['layer1_weights'] = layer1_weights\n",
    "        parameters['layer1_biases'] = layer1_biases\n",
    "        parameters['layer2_weights'] = layer2_weights\n",
    "        parameters['layer2_biases'] = layer2_biases\n",
    "     \n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Forward Propagation\n",
    "    def forward_propagation(self,training_data,parameters,activation):\n",
    "        \n",
    "        value = dict()            #to store the intermediate values for backward propagation\n",
    "        m = len(training_data)    #number of training examples\n",
    "\n",
    "        #get the parameters\n",
    "        layer1_weights = parameters['layer1_weights']\n",
    "        layer1_biases = parameters['layer1_biases']\n",
    "        layer2_weights = parameters['layer2_weights']\n",
    "        layer2_biases = parameters['layer2_biases']\n",
    "    \n",
    "        #forward prop\n",
    "        Output_layer1 = np.matmul(layer1_weights,training_data) + layer1_biases\n",
    "            \n",
    "        if(activation == \"relu\"):\n",
    "            activation1 = self.rectified(Output_layer1)\n",
    "        elif(activation == \"sigmoid\"):\n",
    "            activation1 = self.sigmoid(Output_layer1)\n",
    "        else:\n",
    "            print(\"Select a activation function....Type in relu or sigmoid: \\n Re-run\")\n",
    "          \n",
    "        Output_layer2 = np.matmul(layer2_weights,activation1) + layer2_biases\n",
    "        \n",
    "        #fill in the cache\n",
    "        value['output'] = self.softmax(Output_layer2)\n",
    "        value['activation1'] = activation1\n",
    "      \n",
    "        return value['output'],value['activation1'],Output_layer2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Back propagation\n",
    "    def backward_propagation(self,output,train_dataset,train_labels,activation1,parameters,activationfn):\n",
    "        #BACKWARD PROPAGATION\n",
    "            \n",
    "        #get the parameters\n",
    "        layer2_weights = parameters['layer2_weights']\n",
    "\n",
    "        #Gradient with respect to Z layer2\n",
    "        \n",
    "        #Gradient_z2 = derivative wrt loss * derivative wrt softmax activation\n",
    "        gradient_z2 = train_labels - output\n",
    "\n",
    "        #Gradient with respect to W layer2 \n",
    "        gradient_w2 = np.dot(gradient_z2,activation1.T)\n",
    "            \n",
    "        #gradient with respect to B layer2\n",
    "        gradient_b2 = gradient_z2\n",
    "            \n",
    "        #derivative of a1 --- z1 derivative\n",
    "        if(activationfn == \"relu\"):\n",
    "            derivative_z1 = self.deriv_activation(\"relu\",activation1)\n",
    "        if(activationfn == \"sigmoid\"):\n",
    "            derivative_z1 = self.deriv_activation(\"sigmoid\",activation1)\n",
    "    \n",
    "        #Gradient with respect to Z layer1\n",
    "        gradient_z1 = derivative_z1 * (np.dot(layer2_weights.T,gradient_z2))\n",
    "\n",
    "        #Gradient with respect to W layer1\n",
    "        gradient_w1 = np.dot(gradient_z1,train_dataset.T)\n",
    "            \n",
    "        #gradient with respect to B layer1\n",
    "        gradient_b1 = gradient_z1\n",
    "        \n",
    "        return gradient_w1,gradient_b1,gradient_w2,gradient_b2\n",
    "    \n",
    "    \n",
    "    #Update parameters\n",
    "    def update_parameters(self,learning_rate,gradient_w1,gradient_b1,gradient_w2,gradient_b2,parameters):\n",
    "        \n",
    "        #get the parameters\n",
    "        layer1_weights = parameters['layer1_weights']\n",
    "        layer1_biases = parameters['layer1_biases']\n",
    "        layer2_weights = parameters['layer2_weights']\n",
    "        layer2_biases = parameters['layer2_biases']\n",
    "        \n",
    "        #Update Weights1\n",
    "        layer1_newweight = layer1_weights + ((learning_rate) * gradient_w1)\n",
    "        \n",
    "        #update bias1\n",
    "        layer1_newbias = layer1_biases + ((learning_rate) * gradient_b1)\n",
    "\n",
    "        #update Weights2\n",
    "        layer2_newweight = layer2_weights + ((learning_rate) * gradient_w2)\n",
    "\n",
    "        #update bias2\n",
    "        layer2_newbias = layer2_biases + ((learning_rate) * gradient_b2)\n",
    "            \n",
    "        parameters['layer1_weights'] = layer1_newweight\n",
    "        parameters['layer2_weights'] = layer2_newweight\n",
    "        parameters['layer1_biases'] = layer1_newbias\n",
    "        parameters['layer2_biases'] = layer2_newbias\n",
    "    \n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    #calculate the loss \n",
    "    def cal_loss(self,train_labels,predictions):\n",
    "\n",
    "        #cal loss cross entropy\n",
    "        #-(y log y_hat) - (1-y) log (1-y_hat)\n",
    "        y = train_labels\n",
    "        y_hat = predictions\n",
    "        \n",
    "        #loss = np.sum(((-y) * (np.log(y_hat)))- ((1-y) * np.log(1-y_hat)))\n",
    "        loss  = -np.sum((y) * (np.log(y_hat)))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    #Plotting Loss and Accuracy\n",
    "    def plot_loss(self,J_loss):\n",
    "        #plot loss graph\n",
    "        plt.plot(J_loss)\n",
    "        plt.xlabel(\"No: of Iterations\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def plot_accu(self,Accuracy):\n",
    "        #plot accuracy graph\n",
    "        plt.plot(Accuracy)\n",
    "        plt.xlabel(\"No: of Iterations\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MNIST DATA SET PARAMETERS\n",
      "--------------------------\n",
      "\n",
      "\n",
      "\n",
      "--------Report AND Graphs----------\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_Completedata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6c5768ed60ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n--------Report AND Graphs----------\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_Completedata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_Completelabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_Completedata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_Completelabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'training_Completedata' is not defined"
     ]
    }
   ],
   "source": [
    "#01.  MNIST DATA SET\n",
    "#--------------------------------------------------------\n",
    "print(\"\\n\\nMNIST DATA SET PARAMETERS\\n--------------------------\\n\")\n",
    "NN = Neural_network()\n",
    "\n",
    "print(\"Enter Learning Rate (Recommmended 0.001)   : \") \n",
    "Learning_rate = float(input()) \n",
    "print(\"Enter Hidden Units (Recommmended 100)      : \") \n",
    "Hidden_Units = int(input()) \n",
    "print(\"Enter Batch Size (Recommmended 32)         : \") \n",
    "Batch_Size = int(input()) \n",
    "print(\"Choose Activation Function-->>Type in relu or sigmoid : \") \n",
    "Activation_fn = str(input()) \n",
    "print(\"Enter Iterations (Recommmended 20)         : \") \n",
    "Iterations_epoch = int(input()) \n",
    "\n",
    "print(\"\\n\\n--------Report AND Graphs----------\\n\")\n",
    "NN.model(training_Completedata,training_Completelabels,testing_Completedata,testing_Completelabels,Learning_rate,Hidden_Units,Batch_Size,Activation_fn,Iterations_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Madison_IrrigatedRain DATA SET  PARAMETERS\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "Enter Learning Rate (Recommmended 0.001)   : \n",
      "0.0011\n",
      "Enter Hidden Units (Recommmended 10)      : \n",
      "10\n",
      "Enter Batch Size (Recommmended 32)         : \n",
      "32\n",
      "Choose Activation Function-->>Type in relu or sigmoid : \n",
      "relu\n",
      "Enter Iterations (Recommmended 15)         : \n",
      "15\n",
      "\n",
      "\n",
      "--------Report AND Graphs----------\n",
      "\n",
      "Iteration  : 1  (Epoch)   Accuracy =  64.84903109508787  %\n",
      "Iteration  : 2  (Epoch)   Accuracy =  72.69040108156828  %\n",
      "Iteration  : 3  (Epoch)   Accuracy =  76.34069400630915  %\n",
      "Iteration  : 4  (Epoch)   Accuracy =  77.82785038305543  %\n",
      "Iteration  : 5  (Epoch)   Accuracy =  78.68409193330329  %\n",
      "Iteration  : 6  (Epoch)   Accuracy =  79.11221270842722  %\n",
      "Iteration  : 7  (Epoch)   Accuracy =  79.3600721045516  %\n",
      "Iteration  : 8  (Epoch)   Accuracy =  79.40513744930149  %\n",
      "Iteration  : 9  (Epoch)   Accuracy =  79.40513744930149  %\n",
      "Iteration  : 10  (Epoch)   Accuracy =  79.42767012167643  %\n",
      "Iteration  : 11  (Epoch)   Accuracy =  79.45020279405138  %\n",
      "Iteration  : 12  (Epoch)   Accuracy =  79.49526813880126  %\n",
      "Iteration  : 13  (Epoch)   Accuracy =  79.56286615592609  %\n",
      "Iteration  : 14  (Epoch)   Accuracy =  79.60793150067597  %\n",
      "Iteration  : 15  (Epoch)   Accuracy =  79.60793150067597  %\n",
      "-----------------------------------------------------\n",
      "\n",
      "Test Accuracy =  79.87288135593221  %\n",
      "-----------------------------------------------------\n",
      "\n",
      "Cost_Plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "\n",
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 02. Madison_IrrigatedRain DATA SET \n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"\\n\\nMadison_IrrigatedRain DATA SET  PARAMETERS\\n------------------------------------------\\n\\n\")\n",
    "\n",
    "NN = Neural_network()\n",
    "\n",
    "print(\"Enter Learning Rate (Recommmended 0.001)   : \") \n",
    "Learning = float(input()) \n",
    "print(\"Enter Hidden Units (Recommmended 10)      : \") \n",
    "Hidden = int(input()) \n",
    "print(\"Enter Batch Size (Recommmended 32)         : \") \n",
    "BatchSize = int(input()) \n",
    "print(\"Choose Activation Function-->>Type in relu or sigmoid : \") \n",
    "Activfn = str(input()) \n",
    "print(\"Enter Iterations (Recommmended 15)         : \") \n",
    "Iterations = int(input()) \n",
    "\n",
    "print(\"\\n\\n--------Report AND Graphs----------\\n\")\n",
    "\n",
    "NN.model(X_training,y_training,X_testing,y_testing,Learning,Hidden,BatchSize,Activfn,Iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
